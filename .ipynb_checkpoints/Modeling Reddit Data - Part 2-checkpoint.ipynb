{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Reddit Data\n",
    "This notebook contains the machine learning models to see if we can the models to identify the subreddit of each title. We will be optimizing the following classifications models and measuring their optimal performance:\n",
    "    - LogisticRegression\n",
    "    - RandomForest\n",
    "    - AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words, text\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing    \n",
    "    We will import the data, preprocess the data via CountVectorizer, remove additional StopWords, and train/test split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_data_beautiful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Battle] DataViz Battle for the month of Decem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Topic][Open] Open Discussion Monday — Anybody...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Submitted my thesis today. Here's what the chu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_data_beautiful\n",
       "0  [Battle] DataViz Battle for the month of Decem...                  1\n",
       "1  [Topic][Open] Open Discussion Monday — Anybody...                  1\n",
       "2  Submitted my thesis today. Here's what the chu...                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_data_learned.csv')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "is_data_beautiful    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['is_data_beautiful']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove key words that identifier that is specific to each subreddit to add more challenge and to be able to get better data for EDA. This also ensures that we are buildiong out a process that can be scaled in other situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union(['oc', 'til', 'OC', 'TIL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=stop_words, ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train)\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy for the model is 50.8%, anything above that will be an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.508526\n",
       "0    0.491474\n",
       "Name: is_data_beautiful, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "    We will be running a GridSearch for LogisticRegression, RandomForest, and AdaBoostClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GridSearching the best paramenters for LogisticRegression - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9588491134158581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cs': 15}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV()\n",
    "gr_params_lr = {\n",
    "    'Cs': [1,5,8,10,12,14,15,16,17,20,25,30]\n",
    "}\n",
    "gs_lr = GridSearchCV(lr, param_grid=gr_params_lr)\n",
    "gs_lr.fit(X_train_cv, y_train)\n",
    "print(gs_lr.best_score_)\n",
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GridSearching the best paramenters for LogisticRegression - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625292740046838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cs': 8, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV()\n",
    "gr_params_lr = {\n",
    "    'penalty': ['l1'],\n",
    "    'solver':['liblinear'],\n",
    "    'Cs': [6,8,10,12,14,16,18,20]\n",
    "}\n",
    "gs_lr = GridSearchCV(lr, param_grid=gr_params_lr)\n",
    "gs_lr.fit(X_train_cv, y_train)\n",
    "print(gs_lr.best_score_)\n",
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Since the Lasso GridSearch gave us the best results for LogisticRegression, we will be using those parameters on a basic LogisticRegression to be able to extract all the features and use them in the EDA later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(Cs=8, penalty='l1', solver= 'liblinear')\n",
    "lr.fit(X_train_cv, y_train)\n",
    "lr.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849548645937813"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted neg</th>\n",
       "      <th>predic pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>475</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted neg  predic pos\n",
       "actual neg            475          15\n",
       "actual pos              0         507"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr.predict(X_test_cv)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     columns = ['predicted neg', 'predic pos'],\n",
    "                    index = ['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We will run a GridSearch on the RandomForest to see how well it will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9474740715958515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 40}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "gr_params = {\n",
    "    'n_estimators': [3,5,10,30,40,50,100,150],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth':[None, 3,5,7,10]\n",
    "    \n",
    "}\n",
    "gs = GridSearchCV(rf, gr_params)\n",
    "gs.fit(X_train_cv, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996654399464704"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889669007021064"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted neg</th>\n",
       "      <th>predic pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>481</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted neg  predic pos\n",
       "actual neg            481           9\n",
       "actual pos              2         505"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gs.predict(X_test_cv)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     columns = ['predicted neg', 'predic pos'],\n",
    "                    index = ['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier\n",
    "\n",
    "We are going to run grid search through AdaBoostClassifier to see if we can improve our performance and to see if LogisticRegression or DecisionTreeClassifier would make a better weak learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8324974924774323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_estimator': LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " 'learning_rate': 0.1,\n",
       " 'n_estimators': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "gr_params = {\n",
    "    \n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=1), LogisticRegressionCV()],\n",
    "    'n_estimators': [1,10,25,50,100],\n",
    "    'learning_rate': [.1,.50, .75, 1.0, 1.25, 1.50]\n",
    "}\n",
    "\n",
    "gs_ada = GridSearchCV(ada, param_grid=gr_params)\n",
    "\n",
    "gs_ada.fit(X_test_cv, y_test)\n",
    "print(gs_ada.best_score_)\n",
    "gs_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892271662763466"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ada.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ada.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted neg</th>\n",
       "      <th>predic pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted neg  predic pos\n",
       "actual neg            490           0\n",
       "actual pos              0         507"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gs_ada.predict(X_test_cv)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     columns = ['predicted neg', 'predic pos'],\n",
    "                    index = ['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression c_val score was 0.9632 and the test data was 0.9819\n",
    "- RandomForest c_val score was 0.9491 and the test data set was 0.9880\n",
    "- AdaBoostClassifier c_val score was 0.8324 and the test data was 0.8923\n",
    "\n",
    "Both LR and RF were able to to identify the subreddit highly accurately and with ease. The LR having the highest c_val score would tell me that it is the best model, slightly beating the RF. AdaBoost model's performance was surprisingly the worst and given more time was provided I would take a deeper dive to see if we can improve its performance, but with high performance from the other models and limited time we will put the AdaBoost on the bench.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportation of data for further EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the coefficients of LogisticRegression for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'coef':cv.get_feature_names(),\n",
    "    'val':lr.coef_[0]}).to_csv('Data/coef_exploration.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the model input for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names())\n",
    "model_inputs['is_data_beautiful'] = y_train\n",
    "model_inputs.to_csv('Data/model_input.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
